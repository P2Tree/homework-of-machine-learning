# homework-of-machine-learning
This is the homework code of machine learning course of coursera.org, Andrew Ng

- ex1: Linear Regression with Multiple Variables.

  ​	1 . how to submitting solutions

  ​	2 . implement a simple linear regression

  ​	3 . calculate cost function J(theta)

  ​	4 . implement gradient descent by updating theta in each iteration

  ​	5 . visualizing J(theta)

  ​	6 . [Optional] implement Linear Regression with multiple variables

  ​	7 . [Optional] realize Feature Normalization by subtract the mean value of each feature and divide the standard deviations ob features

  ​	8 . [Optional] Gradient Descent of multiple variables

  ​	9 . [Optional] vector realization

  ​	10 . [Optional] selecting learning rates alpha

  ​	11 . [Optional] implement Normal Equations

- ex2: Logistic Regression.

  ​	1 . Visualizing the data in 2-D coordinate

  ​	2 . Realize sigmoid function

  ​	3 . Realize cost function and gradient

  ​	4 . Leading cost function and gradient to fminunc function

  ​	5 . Run logistic regression

  ​	6 . Regularized logistic regression

  ​	7 . [Optional] Try different regularization parameters for prevents overfitting

- ex3: Multi-class Classification and Neural Network.

- ex4: Neural Networks Learning.

- ex5: Regularized Linear Regression and Bias v.s. Variance.

- ex6: Support Vector Machines.

- ex7: K-means Clustering and Principal Component Analysis.

- ex8: Anomaly Detection and Recommender Systems.

  ​	1 . a simple multivariable Gaussian distribution visualization.

  ​	2 . compute Gaussian estimate arguments mu and sigma2.

  ​	3 . compute epsion to select anomaly sample by using F1 score.

  ​	4 . find the anomaly sample.

  ​	5 . [example] **Recommender Systems** , complete for cost function and gradient of X(user to feature) and Theta(movie to feature), and then regularized them.

  ​

  ​
